# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lSEwZU4AlvkN4dA7eLG-yY5a4WHTsmZ2
"""

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.datasets import fetch_20newsgroups

# Load the 20 Newsgroups dataset
newsgroups_data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))

# Access the documents
documents = newsgroups_data.data

import nltk
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()
preprocessed_documents = []

for document in documents:
    # Tokenization and Lowercasing
    tokens = document.lower().split()
    # Stopword Removal and Stemming
    filtered_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]
    preprocessed_documents.append(" ".join(filtered_tokens))

vectorizer = TfidfVectorizer()
term_document_matrix = vectorizer.fit_transform(preprocessed_documents)

# SVD Decomposition
num_topics = 100
svd = TruncatedSVD(n_components=num_topics)
lsi_matrix = svd.fit_transform(term_document_matrix)

query_document = "Israel vs Palestine"
query = vectorizer.transform([query_document])
query_lsi = svd.transform(query)
cosine_similarities = cosine_similarity(query_lsi, lsi_matrix)

most_similar_documents = np.argsort(cosine_similarities, axis=1)[:, -5:]

for i, document_indices in enumerate(most_similar_documents):
    print(f"Top documents for Query {i + 1}:")
    for index in document_indices:
        similarity_score = cosine_similarities[i][index]
        print(f"Document {index} (Cosine Similarity: {similarity_score:.4f})")

# Print the query matrix
print("Query Matrix:")
print(query_lsi)

# Print the top terms for each LSI topic
terms = vectorizer.get_feature_names_out()
for i, topic in enumerate(svd.components_):
    top_terms = [terms[index] for index in topic.argsort()[::-1][:10]]  # Adjust the number of terms to print as needed
    print(f"Top terms representing Topic {i + 1}: {', '.join(top_terms)}")

